# This is a reusable Deploy stage definition that is parameterised to be reusable
# to support deployment to different environments

parameters:
  - name: stageName
    type: string
  - name: environment
    type: string
  - name: serviceConnection
    type: string
  - name: dependsOn
    type: string
    default: ''
  - name: parameterFile
    type: string
  - name: condition
    type: string

stages:
- stage: ${{parameters.stageName}}
  displayName: 'Deploy ${{parameters.environment}} Infrastructure and Applications'
  condition: ${{parameters.condition}}
  variables:
    - group: Public API Infrastructure - ${{parameters.environment}}
    - group: Public API Infrastructure - ${{parameters.environment}} secrets
  ${{ if not(eq(parameters.dependsOn, '')) }}:
    dependsOn: ${{parameters.dependsOn}}
  jobs:
  - deployment: Deploy
    displayName: 'Deploy ${{parameters.environment}} Infrastructure Bicep template and applications'
    environment: '${{parameters.environment}}'
    strategy:
      runOnce:
        deploy:
          steps:
          - bash: echo "##vso[task.setvariable variable=dataProcessorFunctionAppName;]$(subscription)-ees-papi-fa-processor"
            displayName: 'Set additional pipeline variables'

          - download: EESBuildPipeline
            displayName: 'Download Data Processor Function App ZIP file'
            artifact: 'public-api-data-processor-$(upstreamPipelineBuildNumber)'

          - checkout: self

          - task: AzureCLI@2
            displayName: 'Deploy bicep template to Azure'
            inputs:
              azureSubscription: ${{parameters.serviceConnection}}
              scriptType: bash
              scriptLocation: inlineScript
              inlineScript: |
                set -e
                dataProcessorExists=`az functionapp list --resource-group $(resourceGroupName) --query "[?name=='$(dataProcessorFunctionAppName)']" | jq '. != []'`
                
                if [[ "$dataProcessorExists" == "true" ]]; then
                  echo "Data Processor Function App exists - combining existing appsettings with new ones"
                fi
                
                az deployment group create \
                  --name 'DeployPublicApiInfrastructure$(upstreamPipelineBuildNumber)' \
                  --resource-group $(resourceGroupName) \
                  --template-file $(templateFile) \
                  --parameters ${{parameters.parameterFile}} \
                  --parameters \
                      subscription='$(subscription)' \
                      resourceTags='$(resourceTags)' \
                      publicUrls='$(publicUrls)' \
                      postgreSqlAdminName='$(postgreSqlAdminName)' \
                      postgreSqlAdminPassword='$(postgreSqlAdminPassword)' \
                      postgreSqlFirewallRules='$(maintenanceFirewallRules)' \
                      dockerImagesTag='$(upstreamPipelineBuildNumber)' \
                      deployContainerApp=$(deployContainerApp) \
                      updatePsqlFlexibleServer=$(updatePsqlFlexibleServer) \
                      dataProcessorFunctionAppExists=$dataProcessorExists

          - template: pipeline-variables-from-bicep-outputs-template.yml
            parameters:
              serviceConnection: ${{parameters.serviceConnection}}

          - task: AzureCLI@2
            displayName: 'Deploy Data Processor Function App - update staging slot app settings'
            inputs:
              azureSubscription: ${{parameters.serviceConnection}}
              scriptType: bash
              scriptLocation: inlineScript
              inlineScript: |
                set -e

                az functionapp config appsettings set \
                  --name $(dataProcessorFunctionAppName) \
                  --resource-group $(resourceGroupName) \
                  --slot staging \
                  --settings \
                    "CoreStorage=@Microsoft.KeyVault(VaultName=$(keyVaultName); SecretName=$(coreStorageConnectionStringSecretKey))"

                az webapp config connection-string set \
                  --name $(dataProcessorFunctionAppName) \
                  --resource-group $(resourceGroupName) \
                  --slot staging \
                  --connection-string-type SQLAzure \
                  --settings \
                    "ContentDb=@Microsoft.KeyVault(VaultName=$(keyVaultName); SecretName=$(dataProcessorContentDbConnectionStringSecretKey))"
                
                az webapp config connection-string set \
                  --name $(dataProcessorFunctionAppName) \
                  --resource-group $(resourceGroupName) \
                  --slot staging \
                  --connection-string-type PostgreSQL \
                  --settings \
                    "PublicDataDb=@Microsoft.KeyVault(VaultName=$(keyVaultName); SecretName=$(dataProcessorPsqlConnectionStringSecretKey))"

#          - task: AzureCLI@2
#            displayName: 'Deploy Data Processor Function App - attach Parquet Fileshare to staging slot'
#            inputs:
#              azureSubscription: ${{parameters.serviceConnection}}
#              scriptType: bash
#              scriptLocation: inlineScript
#              inlineScript: |
#                set -e
#
#                fileShareMountExists=`az webapp config storage-account list --resource-group $(resourceGroupName) --name $(dataProcessorFunctionAppName) --slot staging | jq '. != []'`
#
#                if [[ "$fileShareMountExists" == "false" ]]; then
#
#                  az webapp config storage-account add \
#                    --name $(dataProcessorFunctionAppName) \
#                    --resource-group $(resourceGroupName) \
#                    --custom-id $(parquetFileShareName) \
#                    --storage-type AzureFiles \
#                    --account-name $(publicApiStorageAccountName) \
#                    --access-key `az keyvault secret show --name $(publicApiStorageAccessKeySecretKey) --vault-name $(keyVaultName) --query value --output tsv` \
#                    --share-name $(parquetFileShareName) \
#                    --mount-path $(parquetFileShareMountPath) \
#                    --slot 'staging'
#
#                fi

          - task: AzureCLI@2
            displayName: 'Deploy Data Processor Function App - deploy to staging slot'
            inputs:
              azureSubscription: ${{parameters.serviceConnection}}
              scriptType: bash
              scriptLocation: inlineScript
              inlineScript: |
                set -e
                az functionapp deployment source config-zip \
                  --src '$(Pipeline.Workspace)/EESBuildPipeline/public-api-data-processor-$(upstreamPipelineBuildNumber)/GovUk.Education.ExploreEducationStatistics.Public.Data.Processor.zip' \
                  --name $(dataProcessorFunctionAppName) \
                  --resource-group $(resourceGroupName) \
                  --slot staging

          - task: AzureCLI@2
            displayName: 'Deploy Data Processor Function App - swap slots'
            inputs:
              azureSubscription: ${{parameters.serviceConnection}}
              scriptType: bash
              scriptLocation: inlineScript
              inlineScript: |
                set -e
                az functionapp deployment slot swap \
                  --name $(dataProcessorFunctionAppName) \
                  --resource-group $(resourceGroupName) \
                  --slot staging \
                  --target-slot production
#
#          - task: AzureCLI@2
#            displayName: 'Deploy Data Processor Function App - list storage'
#            inputs:
#              azureSubscription: ${{parameters.serviceConnection}}
#              scriptType: bash
#              scriptLocation: inlineScript
#              inlineScript: |
#                set -e
#
#                az webapp config storage-account list \
#                  --name '$(dataProcessorFunctionAppName)' \
#                  --resource-group '$(resourceGroupName)'
#
